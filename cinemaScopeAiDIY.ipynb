{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0])\n",
      "{'genres': ['Drama', 'Adventure', 'Action'], 'budget': ['10-25 million USD']}\n"
     ]
    }
   ],
   "source": [
    "genres = ['Drama', 'Adventure', 'Action', 'Crime', 'Comedy', 'Thriller', 'Animation', 'Mystery', 'Romance', 'Biography']\n",
    "budget_lst = [\n",
    "        \"under 1 million USD\",\n",
    "        \"1-10 million USD\",\n",
    "        \"10-25 million USD\",\n",
    "        \"25-50 million USD\",\n",
    "        \"50 million USD or more\"\n",
    "    ]\n",
    "def split_label(path):\n",
    "    filename = os.path.basename(path)\n",
    "    label_part = filename.strip()[0:16]  # Assuming labels are in the first 16 chars of the filename\n",
    "    genre_bits = label_part[:10]  # First 10 bits for genres\n",
    "    budget_bits = label_part[11:16]  # Next 5 bits for budgets\n",
    "\n",
    "    # Convert string to integers\n",
    "    genres_label = [int(bit) for bit in genre_bits]\n",
    "    budget_label = [int(bit) for bit in budget_bits]  # Assuming one-hot encoded, find index of '1'\n",
    "\n",
    "    return genres_label, budget_label\n",
    "\n",
    "\n",
    "def decode_label(label_part):\n",
    "    genres_label, budget_label = label_part\n",
    "    genres_label = [genres[i] for i in range(len(genres_label)) if genres_label[i] == 1]\n",
    "    budget_label = [budget_lst[i] for i in range(len(budget_label)) if budget_label[i] == 1]\n",
    "    \n",
    "\n",
    "    return {\n",
    "        'genres': genres_label,\n",
    "        'budget': budget_label\n",
    "    }\n",
    "example_path = \"./database/1110000000 00100 10152.jpg\"\n",
    "example_label = split_label(example_path)\n",
    "print(example_label)\n",
    "print(decode_label(example_label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3)\n",
      "(<tf.Tensor: shape=(32, 10), dtype=int32, numpy=\n",
      "array([[1, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
      "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
      "       [1, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, <tf.Tensor: shape=(32, 5), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 1],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0]], dtype=int32)>)\n",
      "277 92 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 11:19:15.313838: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image /= 255.0  # Normalize the image to [0, 1] range\n",
    "    return image, label\n",
    "\n",
    "def create_dataset_from_directory(directory=\"database\"):\n",
    "    paths, genre_labels, budget_labels = [], [], []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):\n",
    "                path = os.path.join(root, file)\n",
    "                paths.append(path)\n",
    "                genre_label, budget_label = split_label(path)\n",
    "                genre_labels.append(genre_label)\n",
    "                budget_labels.append(budget_label)\n",
    "    \n",
    "    # Convert lists to tensor slices\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    genre_label_ds = tf.data.Dataset.from_tensor_slices(genre_labels)\n",
    "    budget_label_ds = tf.data.Dataset.from_tensor_slices(budget_labels)\n",
    "\n",
    "    # Zip the datasets\n",
    "    label_ds = tf.data.Dataset.zip((genre_label_ds, budget_label_ds))\n",
    "    image_label_ds = tf.data.Dataset.zip((path_ds, label_ds))\n",
    "\n",
    "    # Map the load and preprocess function\n",
    "    image_label_ds = image_label_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    return image_label_ds\n",
    "\n",
    "# Example of usage\n",
    "dataset = create_dataset_from_directory()\n",
    "dataset = dataset.shuffle(1000).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Output for inspection\n",
    "for images, labels in dataset.take(1):  # Take 1 batch\n",
    "    print(images.shape)  # Output the shape of images, e.g., (32, 224, 224, 3)\n",
    "    print(labels)        # Output the corresponding labels\n",
    "\n",
    "\n",
    "# Split to train valid test\n",
    "train_size = int(0.6 * len(dataset))\n",
    "valid_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "train_dataset = dataset.take(train_size)\n",
    "valid_dataset = dataset.skip(train_size).take(valid_size)\n",
    "test_dataset = dataset.skip(train_size + valid_size).take(test_size)\n",
    "print(len(train_dataset), len(valid_dataset), len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">186624</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">95,552,000</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ genre_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ budget_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,565</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m,  │        \u001b[38;5;34m896\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m,  │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m186624\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │ \u001b[38;5;34m95,552,000\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ genre_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │      \u001b[38;5;34m5,130\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ budget_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m2,565\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">95,579,087</span> (364.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m95,579,087\u001b[0m (364.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">95,579,087</span> (364.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m95,579,087\u001b[0m (364.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_multi_output_model(num_genres=10, num_budgets=5, input_shape=(224, 224, 3)):\n",
    "    # Define the layers.\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Add some convolutional layers as an example\n",
    "    x = layers.Conv2D(32, kernel_size=(3, 3), activation='relu')(input_layer)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    # Flatten the output\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    # Dense layer with dropout\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Output layer for genres - assuming multi-label classification (binary for each genre)\n",
    "    genre_output = layers.Dense(num_genres, activation='sigmoid', name='genre_output')(x)\n",
    "    \n",
    "    # Output layer for budget - assuming multi-class classification\n",
    "    budget_output = layers.Dense(num_budgets, activation='softmax', name='budget_output')(x)\n",
    "    \n",
    "    # Construct the model\n",
    "    model = models.Model(inputs=input_layer, outputs=[genre_output, budget_output])\n",
    "    \n",
    "    # Compile the model with appropriate loss functions for each output\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss={'genre_output': 'binary_crossentropy', 'budget_output': 'categorical_crossentropy'},\n",
    "                  metrics={'genre_output': 'accuracy', 'budget_output': 'accuracy'})\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "multi_output_model = build_multi_output_model()\n",
    "\n",
    "# Print model summary to see the full architecture\n",
    "multi_output_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 975ms/step - budget_output_accuracy: 0.4092 - genre_output_accuracy: 0.6183 - loss: 2.6478 - val_budget_output_accuracy: 0.5476 - val_genre_output_accuracy: 0.7361 - val_loss: 1.5018 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 1s/step - budget_output_accuracy: 0.6285 - genre_output_accuracy: 0.6895 - loss: 1.3304 - val_budget_output_accuracy: 0.6399 - val_genre_output_accuracy: 0.7544 - val_loss: 1.2986 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 1s/step - budget_output_accuracy: 0.7823 - genre_output_accuracy: 0.6816 - loss: 0.9135 - val_budget_output_accuracy: 0.6732 - val_genre_output_accuracy: 0.7412 - val_loss: 1.2446 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - budget_output_accuracy: 0.8682 - genre_output_accuracy: 0.6674 - loss: 0.6414 - val_budget_output_accuracy: 0.6933 - val_genre_output_accuracy: 0.7052 - val_loss: 1.2804 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 1s/step - budget_output_accuracy: 0.8951 - genre_output_accuracy: 0.6634 - loss: 0.5221 - val_budget_output_accuracy: 0.7130 - val_genre_output_accuracy: 0.6923 - val_loss: 1.3218 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 970ms/step - budget_output_accuracy: 0.9287 - genre_output_accuracy: 0.6612 - loss: 0.3898 - val_budget_output_accuracy: 0.7065 - val_genre_output_accuracy: 0.7089 - val_loss: 1.3292 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 1000ms/step - budget_output_accuracy: 0.9340 - genre_output_accuracy: 0.6667 - loss: 0.3388 - val_budget_output_accuracy: 0.7154 - val_genre_output_accuracy: 0.7449 - val_loss: 1.4372 - learning_rate: 0.0010\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n"
     ]
    }
   ],
   "source": [
    "# Callback to save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    save_best_only=True, \n",
    "    monitor='val_loss', \n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Callback to reduce learning rate when a metric has stopped improving\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.2, \n",
    "    patience=5, \n",
    "    min_lr=0.001\n",
    ")\n",
    "\n",
    "# Callback for early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_genre_output_accuracy',  # Adjusted to the correct metric name\n",
    "    patience=5, \n",
    "    verbose=1, \n",
    "    mode='max', \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming the model and datasets are prepared correctly\n",
    "multi_output_model = build_multi_output_model()\n",
    "\n",
    "# Train the model with added early stopping\n",
    "history = multi_output_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=[checkpoint, reduce_lr, early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation and Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m total_loss, genre_accuracy, budget_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy for Genre Output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenre_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results = multi_output_model.evaluate(test_dataset)\n",
    "total_loss, genre_accuracy, budget_accuracy = results\n",
    "print(f\"Total Loss: {total_loss}\")\n",
    "print(f\"Accuracy for Genre Output: {genre_accuracy}\")\n",
    "print(f\"Accuracy for Budget Output: {budget_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
